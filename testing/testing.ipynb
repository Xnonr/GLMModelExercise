{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8ae697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Indicates to the terminal that this file is not a shell script and must be run as Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbda47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports Required Libraries\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "from math import ceil\n",
    "from math import floor\n",
    "\n",
    "# Imports Methods From Another Python File\n",
    "#from testing import retrieve_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "10fa2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_by_row_count(max_batch_size, test_file_directory, raw_json_data_test_file):\n",
    "    '''\n",
    "    Returns \n",
    "\n",
    "    Keyword Arguments:\n",
    "    max_batch_size --\n",
    "    raw_json_data_test_file -- \n",
    "    '''\n",
    "    \n",
    "    batches_of_content = 1\n",
    "    batched_contents = []\n",
    "    \n",
    "    with open(os.path.join(test_file_directory, raw_json_data_test_file), 'rb') as file:\n",
    "        content = json.load(file)\n",
    "        \n",
    "        if isinstance(content, list) == False:\n",
    "            content = [content]\n",
    "        \n",
    "        length_of_content = len(content)\n",
    "        \n",
    "        print(f'Total Rows of Data: {length_of_content}')\n",
    "        \n",
    "        if length_of_content > max_batch_size:\n",
    "            batches_of_content = ceil(length_of_content / max_batch_size)\n",
    "            \n",
    "            #print(f'Total Batches of Data: {batches_of_content}')\n",
    "            \n",
    "            for batch_number in range(batches_of_content):\n",
    "                \n",
    "                batch_of_content = []\n",
    "                \n",
    "                if batch_number != batches_of_content - 1:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * max_batch_size):(((batch_number + 1) * max_batch_size))]\n",
    "                else:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * max_batch_size):]\n",
    "                    \n",
    "                batched_contents.append(batch_of_content)\n",
    "                \n",
    "        else:\n",
    "            batched_contents.append(content)\n",
    "            \n",
    "    return batched_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aec30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_by_memory_size(max_batch_size, test_file_directory, raw_json_data_test_file):\n",
    "    '''\n",
    "    Returns \n",
    "\n",
    "    Keyword Arguments:\n",
    "    max_batch_size --\n",
    "    raw_json_data_test_file -- \n",
    "    '''\n",
    "    \n",
    "    batches_of_content = 1\n",
    "    batched_contents = []\n",
    "    \n",
    "    with open(os.path.join(test_file_directory, raw_json_data_test_file), 'rb') as file:\n",
    "        content = json.load(file)\n",
    "        \n",
    "        size_of_content = os.path.getsize(raw_json_data_test_file)\n",
    "        length_of_content = len(content)\n",
    "        size_of_row = ceil(size_of_content / length_of_content)\n",
    "        rows_per_batch = floor(max_batch_size / size_of_row)\n",
    "\n",
    "        print(f'Total Size of Data: {size_of_content} Bytes')\n",
    "        print(f'Total Rows of Data: {length_of_content}')\n",
    "        print(f'Approximate Size of Row: {size_of_row} Bytes')\n",
    "        print(f'Rows Per Batch: {rows_per_batch}')\n",
    "        \n",
    "        if size_of_content > max_batch_size:\n",
    "            batches_of_content = ceil(length_of_content / rows_per_batch)\n",
    "            \n",
    "            print(f'Total Batches of Data: {batches_of_content}')\n",
    "            \n",
    "            for batch_number in range(batches_of_content):\n",
    "                \n",
    "                batch_of_content = []\n",
    "                \n",
    "                if batch_number != batches_of_content - 1:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * rows_per_batch):(((batch_number + 1) * rows_per_batch))]\n",
    "                else:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * rows_per_batch):]\n",
    "                    \n",
    "                batched_contents.append(batch_of_content)\n",
    "                \n",
    "        else:\n",
    "            batched_contents.append(content)\n",
    "            \n",
    "    return batched_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d5ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_http_response(raw_json_data):\n",
    "    '''\n",
    "    Returns a List formatted response after sending an HTTP POST request filled with raw JSON data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    raw_json_data -- Raw JSON data used for testing purposes\n",
    "    '''\n",
    "    \n",
    "    api_url = \"http://127.0.0.1:1313/predict\"\n",
    "    \n",
    "    post_headers = {'content-type': 'application/json'}\n",
    "    \n",
    "\n",
    "    \n",
    "    response = requests.post(api_url, \n",
    "                             data = json.dumps(raw_json_data), \n",
    "                             # json = raw_json_data,\n",
    "                             headers = post_headers)\n",
    "    \n",
    "    if (response.status_code != 200):\n",
    "        print('----- Server returned error -----')\n",
    "        print(raw_json_data)\n",
    "        print(response)\n",
    "        print('---------------------------------')\n",
    "        response_json_data = []\n",
    "    else:\n",
    "        response_json_data = response.json()\n",
    "        \n",
    "    # Prints the size of the HTTP response in Bytes\n",
    "    #print(f'Size of HTTP Response: {len(response.content)} Bytes')\n",
    "\n",
    "    return response_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a218117",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_retrieve_http_response(session, raw_json_data):\n",
    "    '''\n",
    "    Returns a List formatted response after sending an HTTP POST request filled with raw JSON data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    raw_json_data -- Raw JSON data used for testing purposes\n",
    "    '''\n",
    "    \n",
    "    api_url = \"http://127.0.0.1:1313/predict\"\n",
    "    \n",
    "    post_headers = {'content-type': 'application/json'}\n",
    "    \n",
    "    #print('Sending')\n",
    "    async with session.post(api_url, data = json.dumps(raw_json_data), headers = post_headers) as response:\n",
    "    \n",
    "        response_json_data = await response.json()\n",
    "        #print('Received')\n",
    "\n",
    "        return response_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278659d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_counts(test_num, test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num - The test number for the given list of predicition dictionaries being passed in\n",
    "    test_preds - A list containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    true_preds_cnt = [0, 0, 2, 24, 215, 2013]\n",
    "    \n",
    "    test_preds_cnt = len(test_preds)\n",
    "    \n",
    "    if test_preds_cnt == true_preds_cnt[test_num]:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        #'passed': test_res,\n",
    "        'expctd': true_preds_cnt[test_num], \n",
    "        'actl': test_preds_cnt\n",
    "    }\n",
    "    \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d7c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_probabilities(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    for pred in test_preds:\n",
    "        pred_prob = float(pred.get('p_hat'))\n",
    "        \n",
    "        if pred_prob < 0.75:\n",
    "            invalid_test_preds.append(pred_prob) \n",
    "    \n",
    "    if len(invalid_test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "        \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ba18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_business_outcomes(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    for pred in test_preds:\n",
    "        pred_prob = float(pred.get('p_hat'))\n",
    "        pred_busns_out = int(pred.get('business_outcome'))\n",
    "        \n",
    "        if pred_busns_out != 1 or (pred_busns_out == 1 and pred_prob < 0.75):\n",
    "            invalid_test_preds.append([busns_out, pred_prob]) \n",
    "    \n",
    "    if len(invalid_test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "        \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ce2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_proper_input_variables(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    if len(test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    else:\n",
    "        true_pred_vars = sorted(\n",
    "            ['x5_saturday', 'x81_July', 'x81_December', 'x31_japan', 'x81_October', \n",
    "             'x5_sunday', 'x31_asia', 'x81_February', 'x91', 'x81_May', \n",
    "             'x5_monday', 'x81_September', 'x81_March', 'x53', 'x81_November', \n",
    "             'x44', 'x81_June', 'x12', 'x5_tuesday', 'x81_August', \n",
    "             'x81_January', 'x62', 'x31_germany', 'x58', 'x56'])\n",
    "\n",
    "        test_preds_df = pd.DataFrame(test_preds)\n",
    "\n",
    "        test_preds_df_clmns = list(test_preds_df.drop(['business_outcome', 'p_hat'], \n",
    "                                                      axis = 1).columns)\n",
    "\n",
    "        test_preds_rows_missing_values = test_preds_df.isnull().any(axis = 1)\n",
    "\n",
    "        test_preds_rows_missing_values = (\n",
    "            list(test_preds_rows_missing_values[test_preds_rows_missing_values == True].index))\n",
    "\n",
    "        if test_preds_df_clmns == true_pred_vars:\n",
    "            if True not in set(test_preds_rows_missing_values):\n",
    "                test_res = True\n",
    "            else:\n",
    "                for index in test_preds_rows_missing_values:\n",
    "                    invalid_test_preds.append(test_preds_df.loc[index].to_dict())\n",
    "                    \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "    \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a40add88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_agglomeration(cnt_dtls, prob_dtls, busns_out_dtls, in_var_dtls):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    cnt_dtls -- \n",
    "    prob_dtls -- \n",
    "    busns_out_dtls -- \n",
    "    in_var_dtls -- \n",
    "    '''\n",
    "    tests_res_dtls = {\n",
    "        #'cnt_passed': cnt_dtls.get('passed'), \n",
    "        'cnt_expctd': cnt_dtls.get('expctd'), \n",
    "        'cnt_actl': cnt_dtls.get('actl'), \n",
    "        'prob_passed': prob_dtls.get('passed'),\n",
    "        'prob_invld_preds': prob_dtls.get('invld_preds'),\n",
    "        'busns_out_passed': busns_out_dtls.get('passed'),\n",
    "        'busns_out_invld_preds': busns_out_dtls.get('invld_preds'), \n",
    "        'in_var_passed': in_var_dtls.get('passed'),\n",
    "        'in_var_invld_preds': in_var_dtls.get('invld_preds')\n",
    "    }\n",
    "    \n",
    "    return tests_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc899039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_batch_prediction_results(test_num, raw_json_data):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num --\n",
    "    raw_json_data -- \n",
    "    '''\n",
    "    \n",
    "    batch_preds = retrieve_http_response(raw_json_data)\n",
    "    \n",
    "    cnt_res_dtls = prediction_results_verify_counts(test_num, batch_preds)\n",
    "    prob_res_dtls = prediction_results_verify_probabilities(batch_preds)\n",
    "    busns_out_res_dtls = prediction_results_verify_business_outcomes(batch_preds)\n",
    "    in_var_res_dtls = prediction_results_verify_proper_input_variables(batch_preds)\n",
    "    \n",
    "    batch_res_dtls = prediction_results_agglomeration(cnt_res_dtls, \n",
    "                                                      prob_res_dtls, \n",
    "                                                      busns_out_res_dtls, \n",
    "                                                      in_var_res_dtls)\n",
    "    \n",
    "    return batch_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b13c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_collect_batch_prediction_results(session, test_num, raw_json_data):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num --\n",
    "    raw_json_data -- \n",
    "    '''\n",
    "    \n",
    "    batch_preds = await async_retrieve_http_response(session, raw_json_data)\n",
    "    \n",
    "    cnt_res_dtls = prediction_results_verify_counts(test_num, batch_preds)\n",
    "    prob_res_dtls = prediction_results_verify_probabilities(batch_preds)\n",
    "    busns_out_res_dtls = prediction_results_verify_business_outcomes(batch_preds)\n",
    "    in_var_res_dtls = prediction_results_verify_proper_input_variables(batch_preds)\n",
    "    \n",
    "    batch_res_dtls = prediction_results_agglomeration(cnt_res_dtls, \n",
    "                                                      prob_res_dtls, \n",
    "                                                      busns_out_res_dtls, \n",
    "                                                      in_var_res_dtls)\n",
    "    \n",
    "    return batch_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e7dbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batch_agglomerated_prediction_results(aglom_batch_preds_res1, aglom_batch_preds_res2):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    aglom_batch_preds_res1 -- \n",
    "    aglom_batch_preds_res1 -- \n",
    "    '''\n",
    "    \n",
    "    merged_tests_res_dtls = {\n",
    "        #'cnt_passed': \n",
    "        'cnt_expctd': aglom_batch_preds_res1.get('cnt_expctd'),\n",
    "        \n",
    "        'cnt_actl': aglom_batch_preds_res1.get('cnt_actl') + aglom_batch_preds_res2.get('cnt_actl'),\n",
    "        \n",
    "        'prob_passed':  (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('prob_passed') == False or \n",
    "                aglom_batch_preds_res2.get('prob_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'prob_invld_preds': aglom_batch_preds_res1.get('prob_invld_preds') + aglom_batch_preds_res2.get('prob_invld_preds'), \n",
    "        \n",
    "        'busns_out_passed': (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('busns_out_passed') == False or \n",
    "                aglom_batch_preds_res2.get('busns_out_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'busns_out_invld_preds': aglom_batch_preds_res1.get('busns_out_invld_preds') + aglom_batch_preds_res2.get('busns_out_invld_preds'), \n",
    "        \n",
    "        'in_var_passed': (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('in_var_passed') == False or \n",
    "                aglom_batch_preds_res2.get('in_var_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'in_var_invld_preds': aglom_batch_preds_res1.get('in_var_invld_preds') + aglom_batch_preds_res2.get('in_var_invld_preds')\n",
    "    }\n",
    "    \n",
    "    return merged_tests_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed6ccb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_merged_batch_prediction_results(test_num, sample_raw_json_data_batches):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num -- \n",
    "    sample_raw_json_data_batches --\n",
    "    '''\n",
    "    \n",
    "    fnl_test_res_dtls = {}\n",
    "    \n",
    "    for batch in sample_raw_json_data_batches:\n",
    "        if not fnl_test_res_dtls:\n",
    "            fnl_test_res_dtls.update(\n",
    "                collect_batch_prediction_results(test_num, \n",
    "                                                 batch))\n",
    "\n",
    "        else:\n",
    "            fnl_test_res_dtls = merge_batch_agglomerated_prediction_results(\n",
    "                fnl_test_res_dtls, collect_batch_prediction_results(test_num, \n",
    "                                                                    batch))\n",
    "            \n",
    "    return fnl_test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392b190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_collect_merged_batch_prediction_results(test_num, sample_raw_json_data_batches):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num -- \n",
    "    sample_raw_json_data_batches --\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "    \n",
    "        tasks = []\n",
    "        for batch in sample_raw_json_data_batches:\n",
    "            tasks.append(asyncio.ensure_future(async_collect_batch_prediction_results(session, test_num, batch)))\n",
    "            \n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        fnl_test_res_dtls = {}\n",
    "        for result in results:\n",
    "            if not fnl_test_res_dtls:\n",
    "                fnl_test_res_dtls.update(result)\n",
    "            else:\n",
    "                fnl_test_res_dtls = merge_batch_agglomerated_prediction_results(fnl_test_res_dtls, result)\n",
    "\n",
    "        return fnl_test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77fa0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_and_test(batch_size, test_num, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    batch_size --\n",
    "    sample_raw_json_data_file --\n",
    "    '''\n",
    "    \n",
    "    starting_time = time.time()\n",
    "    \n",
    "    test_file_dir = '.' # For '.ipynb'\n",
    "    #test_files_directory = os.path.dirname(os.path.abspath(__file__)) # For '.py'\n",
    "    \n",
    "    batched_sample_raw_json_data = batch_by_row_count(batch_size, \n",
    "                                                      test_file_dir, \n",
    "                                                      sample_raw_json_data_file)\n",
    "    \n",
    "    tests_res = collect_merged_batch_prediction_results(test_num, batched_sample_raw_json_data)\n",
    "    \n",
    "    sync_time_to_completion = {time.time() - starting_time}\n",
    "    \n",
    "    return tests_res, sync_time_to_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54a8cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_batch_and_test(batch_size, test_num, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    batch_size --\n",
    "    sample_raw_json_data_file --\n",
    "    '''\n",
    "    \n",
    "    starting_time = time.time()\n",
    "    \n",
    "    test_file_dir = '.' # For '.ipynb'\n",
    "    #test_files_directory = os.path.dirname(os.path.abspath(__file__)) # For '.py'\n",
    "    \n",
    "    batched_sample_raw_json_data = batch_by_row_count(batch_size, \n",
    "                                                      test_file_dir, \n",
    "                                                      sample_raw_json_data_file)\n",
    "    \n",
    "    tests_res = await async_collect_merged_batch_prediction_results(test_num, batched_sample_raw_json_data)\n",
    "    \n",
    "    async_time_to_completion = {time.time() - starting_time}\n",
    "    \n",
    "    return tests_res, async_time_to_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5958ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1_row_v1():\n",
    "    results = batch_and_test(500, 0, 'sample_raw_json_1_row_v1.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e68ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1_row_v2():\n",
    "    results = batch_and_test(500, 1, 'sample_raw_json_1_row_v2.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df008a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_10_rows():\n",
    "    results = batch_and_test(500, 2, 'sample_raw_json_10_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97e382ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_100_rows():\n",
    "    results = batch_and_test(500, 3, 'sample_raw_json_100_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e028806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1000_rows():\n",
    "    results = batch_and_test(500, 4, 'sample_raw_json_1000_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6455d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_10000_rows():\n",
    "    results = batch_and_test(500, 5, 'sample_raw_json_10000_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "107bfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def testing(rows_per_batch):\n",
    "    '''\n",
    "    Runs all tests and prints out their results in a synchronous fashion\n",
    "    '''\n",
    "    \n",
    "    test_list = [\n",
    "        (0, 'sample_raw_json_1_row_v1.json'),\n",
    "        (1, 'sample_raw_json_1_row_v2.json'),\n",
    "        (2, 'sample_raw_json_10_rows.json'),\n",
    "        (3, 'sample_raw_json_100_rows.json'),\n",
    "        (4, 'sample_raw_json_1000_rows.json'),\n",
    "        (5, 'sample_raw_json_10000_rows.json'),\n",
    "    ]\n",
    "    \n",
    "    for test in test_list:\n",
    "        print(f'----- {test[1]} -----')\n",
    "        sync_res, sync_time = batch_and_test(rows_per_batch, test[0], test[1])\n",
    "        async_res, async_time = await async_batch_and_test(rows_per_batch, test[0], test[1])\n",
    "        \n",
    "        sync_time = str(sync_time)\n",
    "        sync_time = round(float(sync_time[1:len(sync_time) - 1]), 3)\n",
    "\n",
    "        async_time = str(async_time)\n",
    "        async_time = round(float(async_time[1:len(async_time) - 1]), 3)\n",
    "        \n",
    "        time_diff = round((sync_time - async_time), 3)\n",
    "        speed_incr = round((((sync_time - async_time) / abs(sync_time)) * 100), 3)\n",
    "        \n",
    "        print(\n",
    "            f'\\n'\n",
    "            f'Time To Completion: \\n'\n",
    "            f'\\tSynchronous = {sync_time} Seconds \\n'\n",
    "            f'\\tAsynchronous = {async_time} Seconds \\n'\n",
    "            f'\\tDifference = {time_diff} Seconds \\n'\n",
    "            f'\\tSpeed Increase = {speed_incr}% \\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b849115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \n",
    "    await testing(100)\n",
    "    await testing(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b68f2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- sample_raw_json_1_row_v1.json -----\n",
      "Total Rows of Data: 1\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.04 Seconds \n",
      "\tAsynchronous = 0.039 Seconds \n",
      "\tDifference = 0.001 Seconds \n",
      "\tSpeed Increase = 2.5% \n",
      "\n",
      "----- sample_raw_json_1_row_v2.json -----\n",
      "Total Rows of Data: 1\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.035 Seconds \n",
      "\tAsynchronous = 0.032 Seconds \n",
      "\tDifference = 0.003 Seconds \n",
      "\tSpeed Increase = 8.571% \n",
      "\n",
      "----- sample_raw_json_10_rows.json -----\n",
      "Total Rows of Data: 10\n",
      "Total Rows of Data: 10\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.042 Seconds \n",
      "\tAsynchronous = 0.046 Seconds \n",
      "\tDifference = -0.004 Seconds \n",
      "\tSpeed Increase = -9.524% \n",
      "\n",
      "----- sample_raw_json_100_rows.json -----\n",
      "Total Rows of Data: 100\n",
      "Total Rows of Data: 100\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.082 Seconds \n",
      "\tAsynchronous = 0.082 Seconds \n",
      "\tDifference = 0.0 Seconds \n",
      "\tSpeed Increase = 0.0% \n",
      "\n",
      "----- sample_raw_json_1000_rows.json -----\n",
      "Total Rows of Data: 1000\n",
      "Total Rows of Data: 1000\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.788 Seconds \n",
      "\tAsynchronous = 0.277 Seconds \n",
      "\tDifference = 0.511 Seconds \n",
      "\tSpeed Increase = 64.848% \n",
      "\n",
      "----- sample_raw_json_10000_rows.json -----\n",
      "Total Rows of Data: 10000\n",
      "Total Rows of Data: 10000\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 7.55 Seconds \n",
      "\tAsynchronous = 2.103 Seconds \n",
      "\tDifference = 5.447 Seconds \n",
      "\tSpeed Increase = 72.146% \n",
      "\n",
      "----- sample_raw_json_1_row_v1.json -----\n",
      "Total Rows of Data: 1\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.029 Seconds \n",
      "\tAsynchronous = 0.031 Seconds \n",
      "\tDifference = -0.002 Seconds \n",
      "\tSpeed Increase = -6.897% \n",
      "\n",
      "----- sample_raw_json_1_row_v2.json -----\n",
      "Total Rows of Data: 1\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.031 Seconds \n",
      "\tAsynchronous = 0.031 Seconds \n",
      "\tDifference = 0.0 Seconds \n",
      "\tSpeed Increase = 0.0% \n",
      "\n",
      "----- sample_raw_json_10_rows.json -----\n",
      "Total Rows of Data: 10\n",
      "Total Rows of Data: 10\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.045 Seconds \n",
      "\tAsynchronous = 0.043 Seconds \n",
      "\tDifference = 0.002 Seconds \n",
      "\tSpeed Increase = 4.444% \n",
      "\n",
      "----- sample_raw_json_100_rows.json -----\n",
      "Total Rows of Data: 100\n",
      "Total Rows of Data: 100\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.084 Seconds \n",
      "\tAsynchronous = 0.088 Seconds \n",
      "\tDifference = -0.004 Seconds \n",
      "\tSpeed Increase = -4.762% \n",
      "\n",
      "----- sample_raw_json_1000_rows.json -----\n",
      "Total Rows of Data: 1000\n",
      "Total Rows of Data: 1000\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 0.539 Seconds \n",
      "\tAsynchronous = 0.496 Seconds \n",
      "\tDifference = 0.043 Seconds \n",
      "\tSpeed Increase = 7.978% \n",
      "\n",
      "----- sample_raw_json_10000_rows.json -----\n",
      "Total Rows of Data: 10000\n",
      "Total Rows of Data: 10000\n",
      "\n",
      "Time To Completion: \n",
      "\tSynchronous = 5.19 Seconds \n",
      "\tAsynchronous = 2.035 Seconds \n",
      "\tDifference = 3.155 Seconds \n",
      "\tSpeed Increase = 60.79% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26ab978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_messages(index1, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns a String message describing the overall test results of the given sample data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    index1 -- \n",
    "    sample_raw_json_data_file -- \n",
    "    '''\n",
    "    \n",
    "    testing_dir = '.'#os.path.dirname(os.path.abspath(__file__))\n",
    "        \n",
    "    test_res_msg = '------------------------------------------------------------\\n'\n",
    "    test_res_msg += f'Test #{index1}: Data = {sample_raw_json_data_file}\\n\\n'\n",
    "        \n",
    "    pred_list = retrieve_http_response(testing_dir, sample_raw_json_data_file)\n",
    "        \n",
    "    test_res1, test_res_dtls1 = prediction_results_count(index1, pred_list)\n",
    "    test_res_msg += f'Results List Length Test: {test_res1}\\n'\n",
    "    test_res_msg += test_res_dtls1\n",
    "\n",
    "    test_res2, failed_tests_lst1 = prediction_results_probabilities(pred_list)\n",
    "        \n",
    "    test_res_msg += f'Results List Probability Test: {test_res2}'\n",
    "        \n",
    "    if len(failed_tests_lst1) > 0:\n",
    "            \n",
    "        for index2 in range(len(failed_tests_lst1)):\n",
    "            test_res_msg += (\n",
    "                f'\\t Prediction #{index2}: p_hat: Expected >= 0.75, Actual = {failed_tests_lst1[index2]}\\n')\n",
    "        \n",
    "    test_res3, failed_tests_lst2 = prediction_results_business_outcomes(pred_list)\n",
    "        \n",
    "    test_res_msg += f'\\n\\nResults List Business Outcome Test: {test_res3}'\n",
    "        \n",
    "    if len(failed_tests_lst2) > 0:\n",
    "            \n",
    "        for index3 in range(len(failed_tests_lst2)):\n",
    "            test_res_msg += f'\\t Prediction #{index3}: (business_outcome, p_hat): Expected (1, >= 0.75)'\n",
    "            test_res_msg += f', Actual = ({failed_tests_lst1[index3][0]}, {failed_tests_lst1[index3][1]})\\n'\n",
    "        \n",
    "    test_res4, failed_tests_lst3 = prediction_results_proper_input_variables(pred_list)\n",
    "        \n",
    "    test_res_msg += f'\\n\\nResults List Input Variables Test: {test_res4}'\n",
    "        \n",
    "    if len(failed_tests_lst3) > 0:\n",
    "            \n",
    "        for index4 in range(len(failed_tests_lst3)):\n",
    "            test_res_msg += f'\\t Prediction #{index4}: Missing Value(s) {failed_tests_lst3[index4]}\\n'\n",
    "        \n",
    "    test_res_msg += '\\n------------------------------------------------------------\\n'\n",
    "           \n",
    "    return test_res_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cda74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
