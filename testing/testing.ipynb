{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8ae697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Indicates to the terminal that this file is not a shell script and must be run as Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbda47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports Required Libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "from math import ceil\n",
    "from math import floor\n",
    "\n",
    "# Imports Methods From Another Python File\n",
    "#from testing import retrieve_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fa2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_by_row_count(max_batch_size, test_file_directory, raw_json_data_test_file):\n",
    "    '''\n",
    "    Returns \n",
    "\n",
    "    Keyword Arguments:\n",
    "    max_batch_size --\n",
    "    raw_json_data_test_file -- \n",
    "    '''\n",
    "    \n",
    "    batches_of_content = 1\n",
    "    batched_contents = []\n",
    "    \n",
    "    with open(os.path.join(test_file_directory, raw_json_data_test_file), 'rb') as file:\n",
    "        content = json.load(file)\n",
    "        \n",
    "        if isinstance(content, list) == False:\n",
    "            content = [content]\n",
    "        \n",
    "        length_of_content = len(content)\n",
    "        \n",
    "        print(f'Total Rows of Data: {length_of_content}')\n",
    "        \n",
    "        if length_of_content > max_batch_size:\n",
    "            batches_of_content = ceil(length_of_content / max_batch_size)\n",
    "            \n",
    "            print(f'Total Batches of Data: {batches_of_content}')\n",
    "            \n",
    "            for batch_number in range(batches_of_content):\n",
    "                \n",
    "                batch_of_content = []\n",
    "                \n",
    "                if batch_number != batches_of_content - 1:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * max_batch_size):(((batch_number + 1) * max_batch_size))]\n",
    "                else:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * max_batch_size):]\n",
    "                    \n",
    "                batched_contents.append(batch_of_content)\n",
    "                \n",
    "        else:\n",
    "            batched_contents.append(content)\n",
    "            \n",
    "    return batched_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aec30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_by_memory_size(max_batch_size, test_file_directory, raw_json_data_test_file):\n",
    "    '''\n",
    "    Returns \n",
    "\n",
    "    Keyword Arguments:\n",
    "    max_batch_size --\n",
    "    raw_json_data_test_file -- \n",
    "    '''\n",
    "    \n",
    "    batches_of_content = 1\n",
    "    batched_contents = []\n",
    "    \n",
    "    with open(os.path.join(test_file_directory, raw_json_data_test_file), 'rb') as file:\n",
    "        content = json.load(file)\n",
    "        \n",
    "        size_of_content = os.path.getsize(raw_json_data_test_file)\n",
    "        length_of_content = len(content)\n",
    "        size_of_row = ceil(size_of_content / length_of_content)\n",
    "        rows_per_batch = floor(max_batch_size / size_of_row)\n",
    "\n",
    "        print(f'Total Size of Data: {size_of_content} Bytes')\n",
    "        print(f'Total Rows of Data: {length_of_content}')\n",
    "        print(f'Approximate Size of Row: {size_of_row} Bytes')\n",
    "        print(f'Rows Per Batch: {rows_per_batch}')\n",
    "        \n",
    "        if size_of_content > max_batch_size:\n",
    "            batches_of_content = ceil(length_of_content / rows_per_batch)\n",
    "            \n",
    "            print(f'Total Batches of Data: {batches_of_content}')\n",
    "            \n",
    "            for batch_number in range(batches_of_content):\n",
    "                \n",
    "                batch_of_content = []\n",
    "                \n",
    "                if batch_number != batches_of_content - 1:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * rows_per_batch):(((batch_number + 1) * rows_per_batch))]\n",
    "                else:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * rows_per_batch):]\n",
    "                    \n",
    "                batched_contents.append(batch_of_content)\n",
    "                \n",
    "        else:\n",
    "            batched_contents.append(content)\n",
    "            \n",
    "    return batched_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d5ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_http_response(raw_json_data):\n",
    "    '''\n",
    "    Returns a List formatted response after sending an HTTP POST request filled with raw JSON data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    raw_json_data -- Raw JSON data used for testing purposes\n",
    "    '''\n",
    "    \n",
    "    api_url = \"http://127.0.0.1:1313/predict\"\n",
    "    \n",
    "    post_headers = {'content-type': 'application/json'}\n",
    "    \n",
    "\n",
    "    \n",
    "    response = requests.post(api_url, \n",
    "                             data = json.dumps(raw_json_data), \n",
    "                             # json = raw_json_data,\n",
    "                             headers = post_headers)\n",
    "    \n",
    "    if (response.status_code != 200):\n",
    "        print('----- Server returned error -----')\n",
    "        print(raw_json_data)\n",
    "        print(response)\n",
    "        print('---------------------------------')\n",
    "        response_json_data = []\n",
    "    else:\n",
    "        response_json_data = response.json()\n",
    "        \n",
    "    # Prints the size of the HTTP response in Bytes\n",
    "    #print(f'Size of HTTP Response: {len(response.content)} Bytes')\n",
    "\n",
    "    return response_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278659d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_counts(test_num, test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num - The test number for the given list of predicition dictionaries being passed in\n",
    "    test_preds - A list containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    true_preds_cnt = [0, 0, 2, 24, 215, 2013]\n",
    "    \n",
    "    test_preds_cnt = len(test_preds)\n",
    "    \n",
    "    if test_preds_cnt == true_preds_cnt[test_num]:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        #'passed': test_res,\n",
    "        'expctd': true_preds_cnt[test_num], \n",
    "        'actl': test_preds_cnt\n",
    "    }\n",
    "    \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d7c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_probabilities(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    for pred in test_preds:\n",
    "        pred_prob = float(pred.get('p_hat'))\n",
    "        \n",
    "        if pred_prob < 0.75:\n",
    "            invalid_test_preds.append(pred_prob) \n",
    "    \n",
    "    if len(invalid_test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "        \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ba18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_business_outcomes(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    for pred in test_preds:\n",
    "        pred_prob = float(pred.get('p_hat'))\n",
    "        pred_busns_out = int(pred.get('business_outcome'))\n",
    "        \n",
    "        if pred_busns_out != 1 or (pred_busns_out == 1 and pred_prob < 0.75):\n",
    "            invalid_test_preds.append([busns_out, pred_prob]) \n",
    "    \n",
    "    if len(invalid_test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "        \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ce2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_proper_input_variables(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    if len(test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    else:\n",
    "        true_pred_vars = sorted(\n",
    "            ['x5_saturday', 'x81_July', 'x81_December', 'x31_japan', 'x81_October', \n",
    "             'x5_sunday', 'x31_asia', 'x81_February', 'x91', 'x81_May', \n",
    "             'x5_monday', 'x81_September', 'x81_March', 'x53', 'x81_November', \n",
    "             'x44', 'x81_June', 'x12', 'x5_tuesday', 'x81_August', \n",
    "             'x81_January', 'x62', 'x31_germany', 'x58', 'x56'])\n",
    "\n",
    "        test_preds_df = pd.DataFrame(test_preds)\n",
    "\n",
    "        test_preds_df_clmns = list(test_preds_df.drop(['business_outcome', 'p_hat'], \n",
    "                                                      axis = 1).columns)\n",
    "\n",
    "        test_preds_rows_missing_values = test_preds_df.isnull().any(axis = 1)\n",
    "\n",
    "        test_preds_rows_missing_values = (\n",
    "            list(test_preds_rows_missing_values[test_preds_rows_missing_values == True].index))\n",
    "\n",
    "        if test_preds_df_clmns == true_pred_vars:\n",
    "            if True not in set(test_preds_rows_missing_values):\n",
    "                test_res = True\n",
    "            else:\n",
    "                for index in test_preds_rows_missing_values:\n",
    "                    invalid_test_preds.append(test_preds_df.loc[index].to_dict())\n",
    "                    \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "    \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eae54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_agglomeration(cnt_dtls, prob_dtls, busns_out_dtls, in_var_dtls):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    cnt_dtls -- \n",
    "    prob_dtls -- \n",
    "    busns_out_dtls -- \n",
    "    in_var_dtls -- \n",
    "    '''\n",
    "    tests_res_dtls = {\n",
    "        #'cnt_passed': cnt_dtls.get('passed'), \n",
    "        'cnt_expctd': cnt_dtls.get('expctd'), \n",
    "        'cnt_actl': cnt_dtls.get('actl'), \n",
    "        'prob_passed': prob_dtls.get('passed'),\n",
    "        'prob_invld_preds': prob_dtls.get('invld_preds'),\n",
    "        'busns_out_passed': busns_out_dtls.get('passed'),\n",
    "        'busns_out_invld_preds': busns_out_dtls.get('invld_preds'), \n",
    "        'in_var_passed': in_var_dtls.get('passed'),\n",
    "        'in_var_invld_preds': in_var_dtls.get('invld_preds')\n",
    "    }\n",
    "    \n",
    "    return tests_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22bc43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_batch_prediction_results(test_num, raw_json_data):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num --\n",
    "    raw_json_data -- \n",
    "    '''\n",
    "    \n",
    "    batch_preds = retrieve_http_response(raw_json_data)\n",
    "    \n",
    "    cnt_res_dtls = prediction_results_verify_counts(test_num, batch_preds)\n",
    "    prob_res_dtls = prediction_results_verify_probabilities(batch_preds)\n",
    "    busns_out_res_dtls = prediction_results_verify_business_outcomes(batch_preds)\n",
    "    in_var_res_dtls = prediction_results_verify_proper_input_variables(batch_preds)\n",
    "    \n",
    "    batch_res_dtls = prediction_results_agglomeration(cnt_res_dtls, \n",
    "                                                      prob_res_dtls, \n",
    "                                                      busns_out_res_dtls, \n",
    "                                                      in_var_res_dtls)\n",
    "    \n",
    "    return batch_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e237079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batch_agglomerated_prediction_results(aglom_batch_preds_res1, aglom_batch_preds_res2):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    aglom_batch_preds_res1 -- \n",
    "    aglom_batch_preds_res1 -- \n",
    "    '''\n",
    "    \n",
    "    merged_tests_res_dtls = {\n",
    "        #'cnt_passed': \n",
    "        'cnt_expctd': aglom_batch_preds_res1.get('cnt_expctd'),\n",
    "        \n",
    "        'cnt_actl': aglom_batch_preds_res1.get('cnt_actl') + aglom_batch_preds_res2.get('cnt_actl'),\n",
    "        \n",
    "        'prob_passed':  (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('prob_passed') == False or \n",
    "                aglom_batch_preds_res2.get('prob_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'prob_invld_preds': aglom_batch_preds_res1.get('prob_invld_preds') + aglom_batch_preds_res2.get('prob_invld_preds'), \n",
    "        \n",
    "        'busns_out_passed': (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('busns_out_passed') == False or \n",
    "                aglom_batch_preds_res2.get('busns_out_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'busns_out_invld_preds': aglom_batch_preds_res1.get('busns_out_invld_preds') + aglom_batch_preds_res2.get('busns_out_invld_preds'), \n",
    "        \n",
    "        'in_var_passed': (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('in_var_passed') == False or \n",
    "                aglom_batch_preds_res2.get('in_var_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'in_var_invld_preds': aglom_batch_preds_res1.get('in_var_invld_preds') + aglom_batch_preds_res2.get('in_var_invld_preds')\n",
    "    }\n",
    "    \n",
    "    return merged_tests_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3fdf6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_merged_batch_prediction_results(test_num, sample_raw_json_data_batches):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num -- \n",
    "    sample_raw_json_data_batches --\n",
    "    '''\n",
    "    \n",
    "    fnl_test_res_dtls = {}\n",
    "    \n",
    "    for batch in sample_raw_json_data_batches:\n",
    "        if not fnl_test_res_dtls:\n",
    "            fnl_test_res_dtls.update(\n",
    "                collect_batch_prediction_results(test_num, \n",
    "                                                 batch))\n",
    "\n",
    "        else:\n",
    "            fnl_test_res_dtls = merge_batch_agglomerated_prediction_results(\n",
    "                fnl_test_res_dtls, collect_batch_prediction_results(test_num, \n",
    "                                                                    batch))\n",
    "            \n",
    "    return fnl_test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710d7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_and_test(batch_size, test_num, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    batch_size --\n",
    "    sample_raw_json_data_file --\n",
    "    '''\n",
    "    \n",
    "    test_file_dir = '.' # For '.ipynb'\n",
    "    #test_files_directory = os.path.dirname(os.path.abspath(__file__)) # For '.py'\n",
    "    \n",
    "    batched_sample_raw_json_data = batch_by_row_count(batch_size, \n",
    "                                                      test_file_dir, \n",
    "                                                      sample_raw_json_data_file)\n",
    "    \n",
    "    tests_res = collect_merged_batch_prediction_results(test_num, batched_sample_raw_json_data)\n",
    "    \n",
    "    return tests_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5958ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1_row_v1():\n",
    "    results = batch_and_test(500, 0, 'sample_raw_json_1_row_v1.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e68ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1_row_v2():\n",
    "    results = batch_and_test(500, 1, 'sample_raw_json_1_row_v2.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df008a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_10_rows():\n",
    "    results = batch_and_test(500, 2, 'sample_raw_json_10_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97e382ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_100_rows():\n",
    "    results = batch_and_test(500, 3, 'sample_raw_json_100_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e028806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1000_rows():\n",
    "    results = batch_and_test(500, 4, 'sample_raw_json_1000_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6455d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_10000_rows():\n",
    "    results = batch_and_test(500, 5, 'sample_raw_json_10000_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "107bfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronous_testing(list_of_tests):\n",
    "    '''\n",
    "    Runs all tests and prints out their results in a synchronous fashion\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    list_of_tests -- A list of test functions to be run\n",
    "    '''\n",
    "    \n",
    "    for test in list_of_tests:\n",
    "        print(test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b03e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asynchronous_testing(list_of_tests):\n",
    "    '''\n",
    "    Runs all tests and prints out their results in an asynchronous fashion\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    list_of_tests -- A list of test functions to be run\n",
    "    '''\n",
    "    \n",
    "    process_pool = mp.Pool(mp.cpu_count())\n",
    "    \n",
    "    for test in list_of_tests:\n",
    "        process_pool.apply_async(print(test()))\n",
    "                             \n",
    "    process_pool.close()\n",
    "    process_pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b849115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    tests = [test_raw_json_1_row_v1, \n",
    "             test_raw_json_1_row_v2, \n",
    "             test_raw_json_10_rows, \n",
    "             test_raw_json_100_rows, \n",
    "             test_raw_json_1000_rows, \n",
    "             test_raw_json_10000_rows]\n",
    "    \n",
    "    starting_time = time.time()\n",
    "    synchronous_testing(tests)\n",
    "    print(f'\\nSynchronous Time To Completion: {time.time() - starting_time} Seconds')\n",
    "    \n",
    "    \n",
    "    starting_time = time.time()\n",
    "    asynchronous_testing(tests)\n",
    "    print(f'\\nASynchronous Time To Completion: {time.time() - starting_time} Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68f2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows of Data: 1\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 10\n",
      "{'cnt_expctd': 2, 'cnt_actl': 2, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 100\n",
      "{'cnt_expctd': 24, 'cnt_actl': 24, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1000\n",
      "Total Batches of Data: 2\n",
      "{'cnt_expctd': 215, 'cnt_actl': 215, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 10000\n",
      "Total Batches of Data: 20\n",
      "{'cnt_expctd': 2013, 'cnt_actl': 2013, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "Synchronous Time To Completion: 5.862231731414795 Seconds\n",
      "Total Rows of Data: 1\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 10\n",
      "{'cnt_expctd': 2, 'cnt_actl': 2, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 100\n",
      "{'cnt_expctd': 24, 'cnt_actl': 24, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1000\n",
      "Total Batches of Data: 2\n",
      "{'cnt_expctd': 215, 'cnt_actl': 215, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 10000\n",
      "Total Batches of Data: 20\n",
      "{'cnt_expctd': 2013, 'cnt_actl': 2013, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "ASynchronous Time To Completion: 5.834028005599976 Seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26ab978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_messages(index1, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns a String message describing the overall test results of the given sample data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    index1 -- \n",
    "    sample_raw_json_data_file -- \n",
    "    '''\n",
    "    \n",
    "    testing_dir = '.'#os.path.dirname(os.path.abspath(__file__))\n",
    "        \n",
    "    test_res_msg = '------------------------------------------------------------\\n'\n",
    "    test_res_msg += f'Test #{index1}: Data = {sample_raw_json_data_file}\\n\\n'\n",
    "        \n",
    "    pred_list = retrieve_http_response(testing_dir, sample_raw_json_data_file)\n",
    "        \n",
    "    test_res1, test_res_dtls1 = prediction_results_count(index1, pred_list)\n",
    "    test_res_msg += f'Results List Length Test: {test_res1}\\n'\n",
    "    test_res_msg += test_res_dtls1\n",
    "\n",
    "    test_res2, failed_tests_lst1 = prediction_results_probabilities(pred_list)\n",
    "        \n",
    "    test_res_msg += f'Results List Probability Test: {test_res2}'\n",
    "        \n",
    "    if len(failed_tests_lst1) > 0:\n",
    "            \n",
    "        for index2 in range(len(failed_tests_lst1)):\n",
    "            test_res_msg += (\n",
    "                f'\\t Prediction #{index2}: p_hat: Expected >= 0.75, Actual = {failed_tests_lst1[index2]}\\n')\n",
    "        \n",
    "    test_res3, failed_tests_lst2 = prediction_results_business_outcomes(pred_list)\n",
    "        \n",
    "    test_res_msg += f'\\n\\nResults List Business Outcome Test: {test_res3}'\n",
    "        \n",
    "    if len(failed_tests_lst2) > 0:\n",
    "            \n",
    "        for index3 in range(len(failed_tests_lst2)):\n",
    "            test_res_msg += f'\\t Prediction #{index3}: (business_outcome, p_hat): Expected (1, >= 0.75)'\n",
    "            test_res_msg += f', Actual = ({failed_tests_lst1[index3][0]}, {failed_tests_lst1[index3][1]})\\n'\n",
    "        \n",
    "    test_res4, failed_tests_lst3 = prediction_results_proper_input_variables(pred_list)\n",
    "        \n",
    "    test_res_msg += f'\\n\\nResults List Input Variables Test: {test_res4}'\n",
    "        \n",
    "    if len(failed_tests_lst3) > 0:\n",
    "            \n",
    "        for index4 in range(len(failed_tests_lst3)):\n",
    "            test_res_msg += f'\\t Prediction #{index4}: Missing Value(s) {failed_tests_lst3[index4]}\\n'\n",
    "        \n",
    "    test_res_msg += '\\n------------------------------------------------------------\\n'\n",
    "           \n",
    "    return test_res_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c385f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows of Data: 1000\n",
      "Total Batches of Data: 4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mbatch_by_row_count\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_raw_json_1000_rows.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(batch_by_row_count(300, '.', 'sample_raw_json_1000_rows.json')[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(batch_by_memory_size(955000, '.', 'sample_raw_json_1000_rows.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_by_row_count(5, '.', 'sample_raw_json_10_rows.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_by_memory_size(10000, '.', 'sample_raw_json_10_rows.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03794e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
