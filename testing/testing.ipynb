{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8ae697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Indicates to the terminal that this file is not a shell script and must be run as Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbda47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports Required Libraries\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "from math import ceil\n",
    "from math import floor\n",
    "\n",
    "# Imports Methods From Another Python File\n",
    "#from testing import retrieve_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fa2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_by_row_count(max_batch_size, test_file_directory, raw_json_data_test_file):\n",
    "    '''\n",
    "    Returns \n",
    "\n",
    "    Keyword Arguments:\n",
    "    max_batch_size --\n",
    "    raw_json_data_test_file -- \n",
    "    '''\n",
    "    \n",
    "    batches_of_content = 1\n",
    "    batched_contents = []\n",
    "    \n",
    "    with open(os.path.join(test_file_directory, raw_json_data_test_file), 'rb') as file:\n",
    "        content = json.load(file)\n",
    "        \n",
    "        if isinstance(content, list) == False:\n",
    "            content = [content]\n",
    "        \n",
    "        length_of_content = len(content)\n",
    "        \n",
    "        print(f'Total Rows of Data: {length_of_content}')\n",
    "        \n",
    "        if length_of_content > max_batch_size:\n",
    "            batches_of_content = ceil(length_of_content / max_batch_size)\n",
    "            \n",
    "            print(f'Total Batches of Data: {batches_of_content}')\n",
    "            \n",
    "            for batch_number in range(batches_of_content):\n",
    "                \n",
    "                batch_of_content = []\n",
    "                \n",
    "                if batch_number != batches_of_content - 1:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * max_batch_size):(((batch_number + 1) * max_batch_size))]\n",
    "                else:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * max_batch_size):]\n",
    "                    \n",
    "                batched_contents.append(batch_of_content)\n",
    "                \n",
    "        else:\n",
    "            batched_contents.append(content)\n",
    "            \n",
    "    return batched_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aec30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_by_memory_size(max_batch_size, test_file_directory, raw_json_data_test_file):\n",
    "    '''\n",
    "    Returns \n",
    "\n",
    "    Keyword Arguments:\n",
    "    max_batch_size --\n",
    "    raw_json_data_test_file -- \n",
    "    '''\n",
    "    \n",
    "    batches_of_content = 1\n",
    "    batched_contents = []\n",
    "    \n",
    "    with open(os.path.join(test_file_directory, raw_json_data_test_file), 'rb') as file:\n",
    "        content = json.load(file)\n",
    "        \n",
    "        size_of_content = os.path.getsize(raw_json_data_test_file)\n",
    "        length_of_content = len(content)\n",
    "        size_of_row = ceil(size_of_content / length_of_content)\n",
    "        rows_per_batch = floor(max_batch_size / size_of_row)\n",
    "\n",
    "        print(f'Total Size of Data: {size_of_content} Bytes')\n",
    "        print(f'Total Rows of Data: {length_of_content}')\n",
    "        print(f'Approximate Size of Row: {size_of_row} Bytes')\n",
    "        print(f'Rows Per Batch: {rows_per_batch}')\n",
    "        \n",
    "        if size_of_content > max_batch_size:\n",
    "            batches_of_content = ceil(length_of_content / rows_per_batch)\n",
    "            \n",
    "            print(f'Total Batches of Data: {batches_of_content}')\n",
    "            \n",
    "            for batch_number in range(batches_of_content):\n",
    "                \n",
    "                batch_of_content = []\n",
    "                \n",
    "                if batch_number != batches_of_content - 1:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * rows_per_batch):(((batch_number + 1) * rows_per_batch))]\n",
    "                else:\n",
    "                    batch_of_content = content[\n",
    "                        (batch_number * rows_per_batch):]\n",
    "                    \n",
    "                batched_contents.append(batch_of_content)\n",
    "                \n",
    "        else:\n",
    "            batched_contents.append(content)\n",
    "            \n",
    "    return batched_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d5ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_http_response(raw_json_data):\n",
    "    '''\n",
    "    Returns a List formatted response after sending an HTTP POST request filled with raw JSON data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    raw_json_data -- Raw JSON data used for testing purposes\n",
    "    '''\n",
    "    \n",
    "    api_url = \"http://127.0.0.1:1313/predict\"\n",
    "    \n",
    "    post_headers = {'content-type': 'application/json'}\n",
    "    \n",
    "\n",
    "    \n",
    "    response = requests.post(api_url, \n",
    "                             data = json.dumps(raw_json_data), \n",
    "                             # json = raw_json_data,\n",
    "                             headers = post_headers)\n",
    "    \n",
    "    if (response.status_code != 200):\n",
    "        print('----- Server returned error -----')\n",
    "        print(raw_json_data)\n",
    "        print(response)\n",
    "        print('---------------------------------')\n",
    "        response_json_data = []\n",
    "    else:\n",
    "        response_json_data = response.json()\n",
    "        \n",
    "    # Prints the size of the HTTP response in Bytes\n",
    "    #print(f'Size of HTTP Response: {len(response.content)} Bytes')\n",
    "\n",
    "    return response_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b5cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_retrieve_http_response(session, raw_json_data):\n",
    "    '''\n",
    "    Returns a List formatted response after sending an HTTP POST request filled with raw JSON data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    raw_json_data -- Raw JSON data used for testing purposes\n",
    "    '''\n",
    "    \n",
    "    api_url = \"http://127.0.0.1:1313/predict\"\n",
    "    \n",
    "    post_headers = {'content-type': 'application/json'}\n",
    "    \n",
    "    #print('Sending')\n",
    "    async with session.post(api_url, data = json.dumps(raw_json_data), headers = post_headers) as response:\n",
    "    \n",
    "        response_json_data = await response.json()\n",
    "        #print('Received')\n",
    "\n",
    "        return response_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278659d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_counts(test_num, test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num - The test number for the given list of predicition dictionaries being passed in\n",
    "    test_preds - A list containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    true_preds_cnt = [0, 0, 2, 24, 215, 2013]\n",
    "    \n",
    "    test_preds_cnt = len(test_preds)\n",
    "    \n",
    "    if test_preds_cnt == true_preds_cnt[test_num]:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        #'passed': test_res,\n",
    "        'expctd': true_preds_cnt[test_num], \n",
    "        'actl': test_preds_cnt\n",
    "    }\n",
    "    \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d7c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_probabilities(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    for pred in test_preds:\n",
    "        pred_prob = float(pred.get('p_hat'))\n",
    "        \n",
    "        if pred_prob < 0.75:\n",
    "            invalid_test_preds.append(pred_prob) \n",
    "    \n",
    "    if len(invalid_test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "        \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ba18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_business_outcomes(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    for pred in test_preds:\n",
    "        pred_prob = float(pred.get('p_hat'))\n",
    "        pred_busns_out = int(pred.get('business_outcome'))\n",
    "        \n",
    "        if pred_busns_out != 1 or (pred_busns_out == 1 and pred_prob < 0.75):\n",
    "            invalid_test_preds.append([busns_out, pred_prob]) \n",
    "    \n",
    "    if len(invalid_test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "        \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ce2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_verify_proper_input_variables(test_preds):\n",
    "    '''\n",
    "    Returns \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_preds - A list of containing dictionaries of prediction results converted from JSON\n",
    "    '''\n",
    "    \n",
    "    test_res = False\n",
    "    invalid_test_preds = []\n",
    "    \n",
    "    if len(test_preds) == 0:\n",
    "        test_res = True\n",
    "        \n",
    "    else:\n",
    "        true_pred_vars = sorted(\n",
    "            ['x5_saturday', 'x81_July', 'x81_December', 'x31_japan', 'x81_October', \n",
    "             'x5_sunday', 'x31_asia', 'x81_February', 'x91', 'x81_May', \n",
    "             'x5_monday', 'x81_September', 'x81_March', 'x53', 'x81_November', \n",
    "             'x44', 'x81_June', 'x12', 'x5_tuesday', 'x81_August', \n",
    "             'x81_January', 'x62', 'x31_germany', 'x58', 'x56'])\n",
    "\n",
    "        test_preds_df = pd.DataFrame(test_preds)\n",
    "\n",
    "        test_preds_df_clmns = list(test_preds_df.drop(['business_outcome', 'p_hat'], \n",
    "                                                      axis = 1).columns)\n",
    "\n",
    "        test_preds_rows_missing_values = test_preds_df.isnull().any(axis = 1)\n",
    "\n",
    "        test_preds_rows_missing_values = (\n",
    "            list(test_preds_rows_missing_values[test_preds_rows_missing_values == True].index))\n",
    "\n",
    "        if test_preds_df_clmns == true_pred_vars:\n",
    "            if True not in set(test_preds_rows_missing_values):\n",
    "                test_res = True\n",
    "            else:\n",
    "                for index in test_preds_rows_missing_values:\n",
    "                    invalid_test_preds.append(test_preds_df.loc[index].to_dict())\n",
    "                    \n",
    "    test_res_dtls = {\n",
    "        'passed': test_res,\n",
    "        'invld_preds': invalid_test_preds\n",
    "    }\n",
    "    \n",
    "    return test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86820dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results_agglomeration(cnt_dtls, prob_dtls, busns_out_dtls, in_var_dtls):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    cnt_dtls -- \n",
    "    prob_dtls -- \n",
    "    busns_out_dtls -- \n",
    "    in_var_dtls -- \n",
    "    '''\n",
    "    tests_res_dtls = {\n",
    "        #'cnt_passed': cnt_dtls.get('passed'), \n",
    "        'cnt_expctd': cnt_dtls.get('expctd'), \n",
    "        'cnt_actl': cnt_dtls.get('actl'), \n",
    "        'prob_passed': prob_dtls.get('passed'),\n",
    "        'prob_invld_preds': prob_dtls.get('invld_preds'),\n",
    "        'busns_out_passed': busns_out_dtls.get('passed'),\n",
    "        'busns_out_invld_preds': busns_out_dtls.get('invld_preds'), \n",
    "        'in_var_passed': in_var_dtls.get('passed'),\n",
    "        'in_var_invld_preds': in_var_dtls.get('invld_preds')\n",
    "    }\n",
    "    \n",
    "    return tests_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf828e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_batch_prediction_results(test_num, raw_json_data):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num --\n",
    "    raw_json_data -- \n",
    "    '''\n",
    "    \n",
    "    batch_preds = retrieve_http_response(raw_json_data)\n",
    "    \n",
    "    cnt_res_dtls = prediction_results_verify_counts(test_num, batch_preds)\n",
    "    prob_res_dtls = prediction_results_verify_probabilities(batch_preds)\n",
    "    busns_out_res_dtls = prediction_results_verify_business_outcomes(batch_preds)\n",
    "    in_var_res_dtls = prediction_results_verify_proper_input_variables(batch_preds)\n",
    "    \n",
    "    batch_res_dtls = prediction_results_agglomeration(cnt_res_dtls, \n",
    "                                                      prob_res_dtls, \n",
    "                                                      busns_out_res_dtls, \n",
    "                                                      in_var_res_dtls)\n",
    "    \n",
    "    return batch_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9ba03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_collect_batch_prediction_results(session, test_num, raw_json_data):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num --\n",
    "    raw_json_data -- \n",
    "    '''\n",
    "    \n",
    "    batch_preds = await async_retrieve_http_response(session, raw_json_data)\n",
    "    \n",
    "    cnt_res_dtls = prediction_results_verify_counts(test_num, batch_preds)\n",
    "    prob_res_dtls = prediction_results_verify_probabilities(batch_preds)\n",
    "    busns_out_res_dtls = prediction_results_verify_business_outcomes(batch_preds)\n",
    "    in_var_res_dtls = prediction_results_verify_proper_input_variables(batch_preds)\n",
    "    \n",
    "    batch_res_dtls = prediction_results_agglomeration(cnt_res_dtls, \n",
    "                                                      prob_res_dtls, \n",
    "                                                      busns_out_res_dtls, \n",
    "                                                      in_var_res_dtls)\n",
    "    \n",
    "    return batch_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a2c251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batch_agglomerated_prediction_results(aglom_batch_preds_res1, aglom_batch_preds_res2):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    aglom_batch_preds_res1 -- \n",
    "    aglom_batch_preds_res1 -- \n",
    "    '''\n",
    "    \n",
    "    merged_tests_res_dtls = {\n",
    "        #'cnt_passed': \n",
    "        'cnt_expctd': aglom_batch_preds_res1.get('cnt_expctd'),\n",
    "        \n",
    "        'cnt_actl': aglom_batch_preds_res1.get('cnt_actl') + aglom_batch_preds_res2.get('cnt_actl'),\n",
    "        \n",
    "        'prob_passed':  (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('prob_passed') == False or \n",
    "                aglom_batch_preds_res2.get('prob_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'prob_invld_preds': aglom_batch_preds_res1.get('prob_invld_preds') + aglom_batch_preds_res2.get('prob_invld_preds'), \n",
    "        \n",
    "        'busns_out_passed': (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('busns_out_passed') == False or \n",
    "                aglom_batch_preds_res2.get('busns_out_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'busns_out_invld_preds': aglom_batch_preds_res1.get('busns_out_invld_preds') + aglom_batch_preds_res2.get('busns_out_invld_preds'), \n",
    "        \n",
    "        'in_var_passed': (\n",
    "            False \n",
    "            if (aglom_batch_preds_res1.get('in_var_passed') == False or \n",
    "                aglom_batch_preds_res2.get('in_var_passed') == False) \n",
    "            else True), \n",
    "        \n",
    "        'in_var_invld_preds': aglom_batch_preds_res1.get('in_var_invld_preds') + aglom_batch_preds_res2.get('in_var_invld_preds')\n",
    "    }\n",
    "    \n",
    "    return merged_tests_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b9e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_merged_batch_prediction_results(test_num, sample_raw_json_data_batches):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num -- \n",
    "    sample_raw_json_data_batches --\n",
    "    '''\n",
    "    \n",
    "    fnl_test_res_dtls = {}\n",
    "    \n",
    "    for batch in sample_raw_json_data_batches:\n",
    "        if not fnl_test_res_dtls:\n",
    "            fnl_test_res_dtls.update(\n",
    "                collect_batch_prediction_results(test_num, \n",
    "                                                 batch))\n",
    "\n",
    "        else:\n",
    "            fnl_test_res_dtls = merge_batch_agglomerated_prediction_results(\n",
    "                fnl_test_res_dtls, collect_batch_prediction_results(test_num, \n",
    "                                                                    batch))\n",
    "            \n",
    "    return fnl_test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdba8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_collect_merged_batch_prediction_results(test_num, sample_raw_json_data_batches):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    test_num -- \n",
    "    sample_raw_json_data_batches --\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "    \n",
    "        tasks = []\n",
    "        for batch in sample_raw_json_data_batches:\n",
    "            tasks.append(asyncio.ensure_future(async_collect_batch_prediction_results(session, test_num, batch)))\n",
    "            \n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        fnl_test_res_dtls = {}\n",
    "        for result in results:\n",
    "            if not fnl_test_res_dtls:\n",
    "                fnl_test_res_dtls.update(result)\n",
    "            else:\n",
    "                fnl_test_res_dtls = merge_batch_agglomerated_prediction_results(fnl_test_res_dtls, result)\n",
    "\n",
    "        return fnl_test_res_dtls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ede7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_and_test(batch_size, test_num, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    batch_size --\n",
    "    sample_raw_json_data_file --\n",
    "    '''\n",
    "    \n",
    "    starting_time = time.time()\n",
    "    \n",
    "    test_file_dir = '.' # For '.ipynb'\n",
    "    #test_files_directory = os.path.dirname(os.path.abspath(__file__)) # For '.py'\n",
    "    \n",
    "    batched_sample_raw_json_data = batch_by_row_count(batch_size, \n",
    "                                                      test_file_dir, \n",
    "                                                      sample_raw_json_data_file)\n",
    "    \n",
    "    tests_res = collect_merged_batch_prediction_results(test_num, batched_sample_raw_json_data)\n",
    "    \n",
    "    print(f'\\nSynchronous Time To Completion: {time.time() - starting_time} Seconds')\n",
    "    \n",
    "    return tests_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d5328df",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_batch_and_test(batch_size, test_num, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    batch_size --\n",
    "    sample_raw_json_data_file --\n",
    "    '''\n",
    "    \n",
    "    starting_time = time.time()\n",
    "    \n",
    "    test_file_dir = '.' # For '.ipynb'\n",
    "    #test_files_directory = os.path.dirname(os.path.abspath(__file__)) # For '.py'\n",
    "    \n",
    "    batched_sample_raw_json_data = batch_by_row_count(batch_size, \n",
    "                                                      test_file_dir, \n",
    "                                                      sample_raw_json_data_file)\n",
    "    \n",
    "    tests_res = await async_collect_merged_batch_prediction_results(test_num, batched_sample_raw_json_data)\n",
    "    \n",
    "    print(f'\\nAsynchronous Time To Completion: {time.time() - starting_time} Seconds')\n",
    "    \n",
    "    return tests_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5958ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1_row_v1():\n",
    "    results = batch_and_test(500, 0, 'sample_raw_json_1_row_v1.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e68ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1_row_v2():\n",
    "    results = batch_and_test(500, 1, 'sample_raw_json_1_row_v2.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df008a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_10_rows():\n",
    "    results = batch_and_test(500, 2, 'sample_raw_json_10_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97e382ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_100_rows():\n",
    "    results = batch_and_test(500, 3, 'sample_raw_json_100_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e028806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_1000_rows():\n",
    "    results = batch_and_test(500, 4, 'sample_raw_json_1000_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6455d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_json_10000_rows():\n",
    "    results = batch_and_test(500, 5, 'sample_raw_json_10000_rows.json')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "107bfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def testing():\n",
    "    '''\n",
    "    Runs all tests and prints out their results in a synchronous fashion\n",
    "    '''\n",
    "    \n",
    "    test_list = [\n",
    "        (500, 0, 'sample_raw_json_1_row_v1.json'),\n",
    "        (500, 1, 'sample_raw_json_1_row_v2.json'),\n",
    "        (500, 2, 'sample_raw_json_10_rows.json'),\n",
    "        (500, 3, 'sample_raw_json_100_rows.json'),\n",
    "        (500, 4, 'sample_raw_json_1000_rows.json'),\n",
    "        (500, 5, 'sample_raw_json_10000_rows.json'),\n",
    "    ]\n",
    "    \n",
    "    for test in test_list:\n",
    "        print(f'----- {test[2]} -----')\n",
    "        print(batch_and_test(test[0], test[1], test[2]))\n",
    "        print(await async_batch_and_test(test[0], test[1], test[2]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b849115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \n",
    "    await testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b68f2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- sample_raw_json_1_row_v1.json -----\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Synchronous Time To Completion: 0.062371015548706055 Seconds\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Asynchronous Time To Completion: 0.03901386260986328 Seconds\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "\n",
      "----- sample_raw_json_1_row_v2.json -----\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Synchronous Time To Completion: 0.03549313545227051 Seconds\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1\n",
      "\n",
      "Asynchronous Time To Completion: 0.033438920974731445 Seconds\n",
      "{'cnt_expctd': 0, 'cnt_actl': 0, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "\n",
      "----- sample_raw_json_10_rows.json -----\n",
      "Total Rows of Data: 10\n",
      "\n",
      "Synchronous Time To Completion: 0.04630088806152344 Seconds\n",
      "{'cnt_expctd': 2, 'cnt_actl': 2, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 10\n",
      "\n",
      "Asynchronous Time To Completion: 0.05094599723815918 Seconds\n",
      "{'cnt_expctd': 2, 'cnt_actl': 2, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "\n",
      "----- sample_raw_json_100_rows.json -----\n",
      "Total Rows of Data: 100\n",
      "\n",
      "Synchronous Time To Completion: 0.0909111499786377 Seconds\n",
      "{'cnt_expctd': 24, 'cnt_actl': 24, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 100\n",
      "\n",
      "Asynchronous Time To Completion: 0.08544516563415527 Seconds\n",
      "{'cnt_expctd': 24, 'cnt_actl': 24, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "\n",
      "----- sample_raw_json_1000_rows.json -----\n",
      "Total Rows of Data: 1000\n",
      "Total Batches of Data: 2\n",
      "\n",
      "Synchronous Time To Completion: 0.5264439582824707 Seconds\n",
      "{'cnt_expctd': 215, 'cnt_actl': 215, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 1000\n",
      "Total Batches of Data: 2\n",
      "\n",
      "Asynchronous Time To Completion: 0.32874083518981934 Seconds\n",
      "{'cnt_expctd': 215, 'cnt_actl': 215, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "\n",
      "----- sample_raw_json_10000_rows.json -----\n",
      "Total Rows of Data: 10000\n",
      "Total Batches of Data: 20\n",
      "\n",
      "Synchronous Time To Completion: 5.077281951904297 Seconds\n",
      "{'cnt_expctd': 2013, 'cnt_actl': 2013, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "Total Rows of Data: 10000\n",
      "Total Batches of Data: 20\n",
      "\n",
      "Asynchronous Time To Completion: 1.9391610622406006 Seconds\n",
      "{'cnt_expctd': 2013, 'cnt_actl': 2013, 'prob_passed': True, 'prob_invld_preds': [], 'busns_out_passed': True, 'busns_out_invld_preds': [], 'in_var_passed': True, 'in_var_invld_preds': []}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26ab978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_messages(index1, sample_raw_json_data_file):\n",
    "    '''\n",
    "    Returns a String message describing the overall test results of the given sample data\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    index1 -- \n",
    "    sample_raw_json_data_file -- \n",
    "    '''\n",
    "    \n",
    "    testing_dir = '.'#os.path.dirname(os.path.abspath(__file__))\n",
    "        \n",
    "    test_res_msg = '------------------------------------------------------------\\n'\n",
    "    test_res_msg += f'Test #{index1}: Data = {sample_raw_json_data_file}\\n\\n'\n",
    "        \n",
    "    pred_list = retrieve_http_response(testing_dir, sample_raw_json_data_file)\n",
    "        \n",
    "    test_res1, test_res_dtls1 = prediction_results_count(index1, pred_list)\n",
    "    test_res_msg += f'Results List Length Test: {test_res1}\\n'\n",
    "    test_res_msg += test_res_dtls1\n",
    "\n",
    "    test_res2, failed_tests_lst1 = prediction_results_probabilities(pred_list)\n",
    "        \n",
    "    test_res_msg += f'Results List Probability Test: {test_res2}'\n",
    "        \n",
    "    if len(failed_tests_lst1) > 0:\n",
    "            \n",
    "        for index2 in range(len(failed_tests_lst1)):\n",
    "            test_res_msg += (\n",
    "                f'\\t Prediction #{index2}: p_hat: Expected >= 0.75, Actual = {failed_tests_lst1[index2]}\\n')\n",
    "        \n",
    "    test_res3, failed_tests_lst2 = prediction_results_business_outcomes(pred_list)\n",
    "        \n",
    "    test_res_msg += f'\\n\\nResults List Business Outcome Test: {test_res3}'\n",
    "        \n",
    "    if len(failed_tests_lst2) > 0:\n",
    "            \n",
    "        for index3 in range(len(failed_tests_lst2)):\n",
    "            test_res_msg += f'\\t Prediction #{index3}: (business_outcome, p_hat): Expected (1, >= 0.75)'\n",
    "            test_res_msg += f', Actual = ({failed_tests_lst1[index3][0]}, {failed_tests_lst1[index3][1]})\\n'\n",
    "        \n",
    "    test_res4, failed_tests_lst3 = prediction_results_proper_input_variables(pred_list)\n",
    "        \n",
    "    test_res_msg += f'\\n\\nResults List Input Variables Test: {test_res4}'\n",
    "        \n",
    "    if len(failed_tests_lst3) > 0:\n",
    "            \n",
    "        for index4 in range(len(failed_tests_lst3)):\n",
    "            test_res_msg += f'\\t Prediction #{index4}: Missing Value(s) {failed_tests_lst3[index4]}\\n'\n",
    "        \n",
    "    test_res_msg += '\\n------------------------------------------------------------\\n'\n",
    "           \n",
    "    return test_res_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffab793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
